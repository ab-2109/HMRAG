{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a266db7e",
   "metadata": {},
   "source": [
    "## Step 1: Clone the Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac4b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ab-2109/HMRAG.git\n",
    "%cd HMRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95236abd",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047520fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f79de87",
   "metadata": {},
   "source": [
    "## Step 3: Install and Setup Ollama (Required for LLM)\n",
    "Note: Ollama needs to run as a service. On Colab, we'll use an alternative approach with HuggingFace models or OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1cf7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Install Ollama (requires background process)\n",
    "# This is complex on Colab - better to use OpenAI API instead\n",
    "\n",
    "# Uncomment if you want to try Ollama on Colab:\n",
    "# !curl -fsSL https://ollama.com/install.sh | sh\n",
    "# import subprocess\n",
    "# import time\n",
    "# # Start Ollama server in background\n",
    "# ollama_process = subprocess.Popen(['ollama', 'serve'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "# time.sleep(5)\n",
    "# # Pull required models\n",
    "# !ollama pull qwen2.5:7b\n",
    "# !ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e68520b",
   "metadata": {},
   "source": [
    "## Step 4: Setup API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291fed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API keys here\n",
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# Store secrets in Colab's secret manager (left sidebar -> Key icon)\n",
    "# Then access them like this:\n",
    "try:\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "    SERPER_API_KEY = userdata.get('SERPER_API_KEY')\n",
    "except:\n",
    "    # Or set directly (not recommended for production)\n",
    "    OPENAI_API_KEY = \"your-openai-api-key-here\"\n",
    "    SERPER_API_KEY = \"your-serper-api-key-here\"\n",
    "\n",
    "print(\"API keys configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee4ac9f",
   "metadata": {},
   "source": [
    "## Step 5: Download ScienceQA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the ScienceQA dataset\n",
    "!bash dataset/download_ScienceQA.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c2de56",
   "metadata": {},
   "source": [
    "## Step 6: Create Required Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b65d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output and working directories\n",
    "!mkdir -p outputs\n",
    "!mkdir -p lightrag_workdir\n",
    "\n",
    "# Check dataset structure\n",
    "!ls -la dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba6c07c",
   "metadata": {},
   "source": [
    "## Step 7: Run Inference (Small Test)\n",
    "Start with a small test run (5 examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5188dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on a small subset first to test\n",
    "!python3 main.py \\\n",
    "    --data_root ./dataset/ScienceQA/data \\\n",
    "    --image_root ./dataset/ScienceQA/images \\\n",
    "    --output_root ./outputs \\\n",
    "    --caption_file ./dataset/ScienceQA/captions.json \\\n",
    "    --working_dir ./lightrag_workdir \\\n",
    "    --serper_api_key \"$SERPER_API_KEY\" \\\n",
    "    --openai_key \"$OPENAI_API_KEY\" \\\n",
    "    --test_split test \\\n",
    "    --test_number 5 \\\n",
    "    --shot_number 0 \\\n",
    "    --label test_run \\\n",
    "    --save_every 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4337dc11",
   "metadata": {},
   "source": [
    "## Step 8: Run Full Inference\n",
    "After testing, run on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6099f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full inference run\n",
    "!python3 main.py \\\n",
    "    --data_root ./dataset/ScienceQA/data \\\n",
    "    --image_root ./dataset/ScienceQA/images \\\n",
    "    --output_root ./outputs \\\n",
    "    --caption_file ./dataset/ScienceQA/captions.json \\\n",
    "    --working_dir ./lightrag_workdir \\\n",
    "    --serper_api_key \"$SERPER_API_KEY\" \\\n",
    "    --openai_key \"$OPENAI_API_KEY\" \\\n",
    "    --test_split test \\\n",
    "    --shot_number 2 \\\n",
    "    --label full_run \\\n",
    "    --save_every 50 \\\n",
    "    --use_caption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec69152",
   "metadata": {},
   "source": [
    "## Step 9: View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0efdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View output files\n",
    "!ls -lh outputs/\n",
    "\n",
    "# Load and display results\n",
    "import json\n",
    "\n",
    "with open('outputs/test_run_test.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "print(f\"Total results: {len(results)}\")\n",
    "print(\"\\nSample results:\")\n",
    "for qid, answer in list(results.items())[:5]:\n",
    "    print(f\"Question ID: {qid}, Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5964324d",
   "metadata": {},
   "source": [
    "## Alternative: Use OpenAI Models Directly\n",
    "If Ollama setup is difficult, modify the agents to use OpenAI API directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14d9c70",
   "metadata": {},
   "source": [
    "## Download Results to Local Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8f74e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download results\n",
    "from google.colab import files\n",
    "\n",
    "# Download the results file\n",
    "files.download('outputs/test_run_test.json')\n",
    "\n",
    "# Or zip and download all outputs\n",
    "!zip -r outputs.zip outputs/\n",
    "files.download('outputs.zip')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
